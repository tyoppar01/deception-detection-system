{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import os, sys, glob, csv, keras\n",
    "import os.path as path\n",
    "from keras import models, layers, optimizers, preprocessing as KRSpreps, utils as KRSutils\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary and store paths for all different Modalities(Micro-expression and Gaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {}\n",
    "data_path['gazedata_path'] = \"Gaze_Features/\"\n",
    "data_path['mexpdata_path'] = \"Mexp_Features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/jingweiong/Downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking No. of files in each of Micro-expression & Gaze Folders && Shape of the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of file in gazedata_path:  473\n",
      "No. of file in mexpdata_path:  473\n"
     ]
    }
   ],
   "source": [
    "data_shape_all = pd.DataFrame()\n",
    "for key in data_path.keys():\n",
    "    count = 0\n",
    "    data_shape, file_names = [], []\n",
    "    for filepath in glob(path.join(data_path[key], '*.csv')):\n",
    "        file_shape = pd.read_csv(filepath).shape\n",
    "        filename = path.basename(filepath)\n",
    "        for reps in ((\"Gaze_\", \"\"), (\"Mexp_\", \"\")):\n",
    "            filename = filename.replace(*reps)\n",
    "        if filename not in ['Annotation_mexp_features.csv', 'Annotation_gaze_features.csv', 'Youtube_splitsteal_deception_user5_3.csv']:\n",
    "            data_shape.append([file_shape[0], file_shape[1]])\n",
    "            file_names.append(filename)\n",
    "            count+=1\n",
    "    data_shape = pd.DataFrame(data_shape)\n",
    "    data_shape.columns = [key + str(0), key +str(1)]\n",
    "    data_shape.index = pd.Series(file_names)\n",
    "    data_shape_all = pd.concat([data_shape_all, data_shape], axis = 1, sort=True)\n",
    "    print(f\"No. of file in {key}: \", count)\n",
    "#data_shape_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dictionaries of Micro-expression & Gaze\n",
    "Remove Initials and Make the Keys Same for the Same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_dict, mexp_dict = {}, {}\n",
    "listofdicts = [gaze_dict, mexp_dict]\n",
    "for key, data_dict_indiv in zip(data_path.keys(), listofdicts):\n",
    "    for filepath in glob(path.join(data_path[key], '*.csv')):\n",
    "        data = pd.read_csv(filepath)\n",
    "        filename = path.basename(filepath)\n",
    "        for reps in ((\"Gaze_\", \"\"), (\"Mexp_\", \"\")):\n",
    "            filename = filename.replace(*reps)\n",
    "        data_dict_indiv[filename] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking If the Labels are Same for Same Keys in Each Dcitionaries & Separating Labels from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of files with same label:  473\n"
     ]
    }
   ],
   "source": [
    "filename_dictkeys = list(gaze_dict)\n",
    "label_dict = {}\n",
    "for key in filename_dictkeys:\n",
    "    # print(key)\n",
    "    gazedata, mexpdata = gaze_dict[key], mexp_dict[key]\n",
    "    label_gaze = gazedata.loc[:, \"label\"].unique()[0]\n",
    "    label_mexp = mexpdata.loc[:, \"label\"].unique()[0]\n",
    "    label_set = set([label_gaze, label_mexp])\n",
    "    if len(label_set) > 1:\n",
    "        print(key)\n",
    "    else:\n",
    "        label_dict[key] = list(label_set)[0]\n",
    "print(\"No. of files with same label: \", len(label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Indexing Columns & Labels from Training Data && Reindexing with TIme && Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "filename_dictkeys = list(gaze_dict)\n",
    "gaze_dict_upsampled, mexp_dict_upsampled = {}, {}\n",
    "for key in filename_dictkeys:\n",
    "    gaze_data = gaze_dict[key]\n",
    "    if \"Unnamed: 0\" in gaze_data.columns:\n",
    "        gaze_data = gaze_data.drop(\"Unnamed: 0\", axis=1)\n",
    "    else:\n",
    "        print(f\"Warning: 'Unnamed: 0' column not found in '{key}'\")\n",
    "    \n",
    "    # Drop other columns like \"frame\" and \"label\"\n",
    "    gaze_data = gaze_data.drop([\"frame\", \"label\", \"face_id\", \"timestamp\", \"confidence\", \"success\"], axis=1, errors='ignore')\n",
    "    gaze_data = np.array(gaze_data.drop_duplicates())\n",
    "    gaze_dict_upsampled[key] = resample(gaze_data, 300)\n",
    "\n",
    "    mexp_data = mexp_dict[key]\n",
    "    if \"Unnamed: 0\" in mexp_data.columns:\n",
    "        mexp_data = mexp_data.drop(\"Unnamed: 0\", axis=1)\n",
    "    else:\n",
    "        print(f\"Warning: 'Unnamed: 0' column not found in '{key}'\")\n",
    "    \n",
    "    # Drop other columns like \"frame\" and \"label\"\n",
    "    mexp_data = mexp_data.drop([\"frame\", \"label\", \"face_id\", \"timestamp\", \"confidence\", \"success\"], axis=1, errors='ignore')\n",
    "    mexp_data = np.array(mexp_data.drop_duplicates())\n",
    "    mexp_dict_upsampled[key] = resample(mexp_data, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3986)\n",
    "train_split_keys = random.sample(list(gaze_dict_upsampled), int(0.80*len(list(gaze_dict_upsampled))))\n",
    "test_split_keys = list(set(list(gaze_dict_upsampled)) - set(train_split_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_train = lambda dict_data: {key: value for key, value in dict_data.items() if key in train_split_keys}\n",
    "dict_split_test = lambda dict_data: {key: value for key, value in dict_data.items() if key in test_split_keys}\n",
    "\n",
    "mapped_train = list(map(dict_split_train, [gaze_dict_upsampled, mexp_dict_upsampled, label_dict]))\n",
    "mapped_test = list(map(dict_split_test, [gaze_dict_upsampled, mexp_dict_upsampled, label_dict]))\n",
    "\n",
    "train_data = {'gaze_train': mapped_train[0], 'mexp_train': mapped_train[1], 'y_train': mapped_train[2]}\n",
    "test_data = {'gaze_test': mapped_test[0], 'mexp_test': mapped_test[1], 'y_test': mapped_test[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2arr = lambda x: np.array(x)\n",
    "\n",
    "train_data['gaze_train'] = conv2arr(list(train_data['gaze_train'].values()))\n",
    "test_data['gaze_test'] = conv2arr(list(test_data['gaze_test'].values()))\n",
    "\n",
    "train_data['mexp_train'] = conv2arr(list(train_data['mexp_train'].values()))\n",
    "test_data['mexp_test'] = conv2arr(list(test_data['mexp_test'].values()))\n",
    "\n",
    "train_data['y_train'] = conv2arr(list(train_data['y_train'].values()))\n",
    "test_data['y_test'] = conv2arr(list(test_data['y_test'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 300, 292)\n",
      "(113400, 292)\n",
      "(95, 300, 292)\n",
      "(28500, 292)\n",
      "(113400, 292) (28500, 292)\n",
      "(378, 300, 45)\n",
      "(113400, 45)\n",
      "(95, 300, 45)\n",
      "(28500, 45)\n",
      "(113400, 45) (28500, 45)\n"
     ]
    }
   ],
   "source": [
    "train_key, test_key = list(train_data.keys()), list(test_data.keys())\n",
    "train_key.remove('y_train')\n",
    "test_key.remove('y_test')\n",
    "\n",
    "for key1, key2 in zip(train_key, test_key):\n",
    "    scaler = StandardScaler()\n",
    "    data1, data2 = train_data[key1], test_data[key2]\n",
    "\n",
    "    s0, s1, s2 = data1.shape[0], data1.shape[1], data1.shape[2]\n",
    "    print(data1.shape)\n",
    "    data1 = data1.reshape(s0*s1, s2)\n",
    "    data1 = scaler.fit_transform(data1)\n",
    "    print(data1.shape)\n",
    "    train_data[key1] = data1.reshape(s0, s1, s2)\n",
    "\n",
    "    s0, s1, s2 = data2.shape[0], data2.shape[1], data2.shape[2]\n",
    "    print(data2.shape)\n",
    "    data2 = data2.reshape(s0*s1, s2)\n",
    "    data2 = scaler.transform(data2)\n",
    "    print(data2.shape)\n",
    "    test_data[key2] = data2.reshape(s0, s1, s2)\n",
    "    print(data1.shape, data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaze train shape: (378, 300, 292)\n",
      "Mexp train shape: (378, 300, 45)\n",
      "Gaze test shape: (95, 300, 292)\n",
      "mexp test shape: (95, 300, 45)\n"
     ]
    }
   ],
   "source": [
    "gaze_features = train_data['gaze_train'].copy()\n",
    "test_gaze_features = test_data['gaze_test'].copy()\n",
    "\n",
    "mexp_features = train_data['mexp_train'].copy()\n",
    "test_mexp_features = test_data['mexp_test'].copy()\n",
    "\n",
    "gaze_features = np.clip(gaze_features, -5, 5)\n",
    "mexp_features = np.clip(mexp_features, -5, 5)\n",
    "\n",
    "test_gaze_features = np.clip(test_gaze_features, -5, 5)\n",
    "test_mexp_features = np.clip(test_mexp_features, -5, 5)\n",
    "\n",
    "print('Gaze train shape:', gaze_features.shape)\n",
    "print('Mexp train shape:', mexp_features.shape)\n",
    "\n",
    "print('Gaze test shape:', test_gaze_features.shape)\n",
    "print('mexp test shape:', test_mexp_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(train_data['y_train']).apply(lambda value: 0 if value == 'Truthful' else 1)\n",
    "y_test = pd.Series(test_data['y_test']).apply(lambda value: 0 if value == 'Truthful' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Deceptive       0.59      0.44      0.51        45\n",
      "    Truthful       0.59      0.72      0.65        50\n",
      "\n",
      "    accuracy                           0.59        95\n",
      "   macro avg       0.59      0.58      0.58        95\n",
      "weighted avg       0.59      0.59      0.58        95\n",
      "\n",
      "Testing Accuracy: 0.5894736842105263\n",
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenate gaze and microexpression features for training and testing\n",
    "X_train = np.concatenate((gaze_features, mexp_features), axis=2)\n",
    "X_test = np.concatenate((test_gaze_features, test_mexp_features), axis=2)\n",
    "\n",
    "# Reshape the features to 2D for SVM\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Train labels\n",
    "y_train = train_data['y_train']\n",
    "y_test = test_data['y_test']\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear') #, C=1.0, random_state=42\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svm_model.predict(X_train)\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Deceptive       0.88      0.31      0.46        45\n",
      "    Truthful       0.61      0.96      0.74        50\n",
      "\n",
      "    accuracy                           0.65        95\n",
      "   macro avg       0.74      0.64      0.60        95\n",
      "weighted avg       0.73      0.65      0.61        95\n",
      "\n",
      "Testing Accuracy: 0.6526315789473685\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm_model_poly = SVC(kernel='poly') #, C=1.0, random_state=42\n",
    "svm_model_poly.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svm_model_poly.predict(X_train)\n",
    "y_pred_test = svm_model_poly.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Deceptive       0.80      0.27      0.40        45\n",
      "    Truthful       0.59      0.94      0.72        50\n",
      "\n",
      "    accuracy                           0.62        95\n",
      "   macro avg       0.69      0.60      0.56        95\n",
      "weighted avg       0.69      0.62      0.57        95\n",
      "\n",
      "Testing Accuracy: 0.6210526315789474\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='rbf') #, C=1.0, random_state=42\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svm_model.predict(X_train)\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Deceptive       0.50      0.42      0.46        45\n",
      "    Truthful       0.54      0.62      0.58        50\n",
      "\n",
      "    accuracy                           0.53        95\n",
      "   macro avg       0.52      0.52      0.52        95\n",
      "weighted avg       0.52      0.53      0.52        95\n",
      "\n",
      "Testing Accuracy: 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='sigmoid') #, C=1.0, random_state=42\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svm_model.predict(X_train)\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multimodal_mexp_and_gaze.pkl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_model_poly, 'multimodal_mexp_and_gaze.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deceptive']\n",
      "Deceptive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def preprocess_data_with_pca(filepath, n_samples, expected_features):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data = data.drop(columns=[\"Unnamed: 0\", \"frame\", \"label\", \"face_id\", \"timestamp\", \"confidence\", \"success\"], errors='ignore')\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    # Resample to a fixed number of samples\n",
    "    if len(data) > n_samples:\n",
    "        data = resample(data, n_samples)\n",
    "    elif len(data) < n_samples:\n",
    "        repeat_factor = n_samples // len(data) + 1\n",
    "        data = pd.DataFrame(np.tile(data, (repeat_factor, 1)), columns=data.columns)[:n_samples]\n",
    "\n",
    "    # PCA for dimensionality reduction if the number of features is more than expected\n",
    "    if data.shape[1] > expected_features:\n",
    "        pca = PCA(n_components=expected_features)\n",
    "        data = pca.fit_transform(data)\n",
    "    elif data.shape[1] < expected_features:\n",
    "        raise ValueError(f\"Data has fewer features ({data.shape[1]}) than expected ({expected_features}).\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def predict_deception(gaze_filepath, mexp_filepath, svm_model, gaze_features=292, mexp_features=45):\n",
    "    # Preprocess gaze data with PCA\n",
    "    gaze_data = preprocess_data_with_pca(gaze_filepath, n_samples=300, expected_features=gaze_features)\n",
    "\n",
    "    # Preprocess microexpression data with PCA\n",
    "    mexp_data = preprocess_data_with_pca(mexp_filepath, n_samples=300, expected_features=mexp_features)\n",
    "\n",
    "    # Concatenate gaze and microexpression features\n",
    "    features = np.concatenate((gaze_data, mexp_data), axis=1).reshape(1, -1)\n",
    "\n",
    "    # Use a pre-trained SimpleImputer or ensure it is fitted with the training data\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features = imputer.fit_transform(features)  # It's better to fit this with training data only\n",
    "\n",
    "    # Predict using the SVM model\n",
    "    prediction = svm_model.predict(features)\n",
    "    print(prediction)\n",
    "\n",
    "    # Return the result\n",
    "    return 'Deceptive' if prediction == 'Deceptive' else 'truthful'\n",
    "\n",
    "# Example usage\n",
    "gaze_file = \"/Users/jingweiong/Downloads/Gaze_Features/Gaze_reallifedeception_trial_truth_015.csv\"\n",
    "mexp_file = \"/Users/jingweiong/Downloads/Mexp_Features/Mexp_reallifedeception_trial_truth_015.csv\"\n",
    "\n",
    "result = predict_deception(gaze_file, mexp_file, svm_model, gaze_features=292, mexp_features=45)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
